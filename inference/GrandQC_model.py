"""
Grand Challenge QC Tissue Detection Script

This script performs automated tissue detection on whole slide images (WSI)
using a pre-trained UNet++ model. It processes slides at 10 MPP resolution,
applies patch-based inference, and generates tissue masks.

Features:
- Handles variable slide sizes through patch-based processing
- Applies JPEG compression to match training conditions
- Generates color-coded tissue masks
- Supports CUDA acceleration

Dependencies:
- openslide-python
- opencv-python
- numpy
- torch
- PIL
- segmentation-models-pytorch
"""

import os
import shutil
from typing import Any

import cv2
import numpy as np
import segmentation_models_pytorch as smp
import torch
from PIL import Image
from tiatoolbox.models.engine.semantic_segmentor import (
    IOSegmentorConfig,
    SemanticSegmentor,
)
from tiatoolbox.models.models_abc import ModelABC
from tiatoolbox.wsicore.wsireader import WSIReader


class GrandQCModel(ModelABC):
    """Example model which can be used for image blurring."""

    def __init__(self, grandQC_Model: torch.nn.Module) -> None:
        """Initialize BlurModel."""
        super().__init__()
        self._postproc = self.postproc
        self._preproc = self.preproc
        self.grandQC_Model = grandQC_Model

    @staticmethod
    def preproc(image: np.ndarray) -> np.ndarray:
        """ImageNet normalise function."""
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        normalised = (image / 255.0 - mean) / std
        return normalised

    @staticmethod
    def postproc(image: np.ndarray) -> np.ndarray:
        """Post-processing function."""
        return image

    def forward(
        self,
        imgs: torch.Tensor,
        *args: tuple[Any, ...],  # skipcq: PYL-W0613  # noqa: ARG002
        **kwargs: dict,  # skipcq: PYL-W0613  # noqa: ARG002
    ) -> torch.Tensor:
        """Forward function for model."""
        output = self.grandQC_Model(imgs)
        return output

    @staticmethod
    def infer_batch(
        model: torch.nn.Module,
        batch_data: torch.Tensor,
        *,
        device: str,
    ) -> list:
        """Run inference on an input batch.

        This contains logic for forward operation as well as i/o
        aggregation.

        Args:
            model (nn.Module):
                PyTorch defined model.
            batch_data (:class:`torch.Tensor`):
                A batch of data generated by
                `torch.utils.data.DataLoader`.
            device (str):
                Transfers model to the specified device. Default is "cpu".
        aggregation.

        Args:
            model (nn.Module):
                PyTorch defined model.
            batch_data (:class:`torch.Tensor`):
                A batch of data generated by
                `torch.utils.data.DataLoader`.
            device (str):
                Transfers model to the specified device. Default is "cpu".

        Returns:
            list:
                List of network output head, each output is an
                :class:`numpy.ndarray`.

        """
        model.eval()

        ####
        imgs = batch_data

        imgs = imgs.to(device).type(torch.float32)
        imgs = imgs.permute(0, 3, 1, 2)  # to NCHW

        with torch.inference_mode():
            logits = model(imgs)
            probs = torch.nn.functional.softmax(logits, 1)
            probs = probs.permute(0, 2, 3, 1)  # to NHWC

        probs = probs.cpu().numpy()
        return [probs]


# Configuration constants
DEVICE = "cuda"
DETECTION_MPP = 10
PATCH_SIZE = 512
ENCODER = "timm-efficientnet-b0"
JPEG_QUALITY = 80

# Directory paths
SLIDE_DIR = "/media/u1910100/data/slides"
OUTPUT_DIR = "/media/u1910100/data/overlays"
MODEL_WEIGHT_PATH = "/media/u1910100/data/GrandQC_Tissue_Detection_MPP10.pth"


def get_slide_names():
    """Get sorted list of slide files from the slide directory."""
    return sorted(
        [f for f in os.listdir(SLIDE_DIR) if os.path.isfile(os.path.join(SLIDE_DIR, f))]
    )


def apply_jpeg_compression(image):
    """Apply JPEG compression to reproduce training conditions."""
    image_array = np.array(image)
    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY]
    _, compressed = cv2.imencode(".jpg", image_array, encode_param)
    return cv2.imdecode(compressed, 1)


def process_single_slide(slide_path: str, model_weights_path: str):
    """Process a single slide for tissue detection.

    Args:
        slide_path (str): Full path to the slide file
        model_weights_path (str): Full path to the model weights file

    Returns:
        numpy.ndarray: Predicted tissue mask, or None if processing failed
    """
    # Load and initialize model
    model = smp.UnetPlusPlus(
        encoder_name=ENCODER,
        encoder_weights=None,
        classes=2,
        activation=None,
    )

    model.load_state_dict(torch.load(model_weights_path, map_location="cpu"))
    model.to(DEVICE)
    model.eval()

    grandQC_model = GrandQCModel(model)

    # slide = OpenSlide(slide_path)
    slide_reader = WSIReader.open(slide_path)

    # Get thumbnail at target MPP
    image_original = slide_reader.slide_thumbnail(resolution=DETECTION_MPP, units="mpp")

    # Apply JPEG compression to match training conditions
    compressed_image = apply_jpeg_compression(image_original)
    processed_image = Image.fromarray(compressed_image)
    processed_image.save("./temp_compressed_image.jpg")

    # Defining ioconfig
    iostate = IOSegmentorConfig(
        input_resolutions=[
            {"units": "baseline", "resolution": 1.0},
        ],
        output_resolutions=[
            {"units": "baseline", "resolution": 1.0},
        ],
        patch_input_shape=[512, 512],
        patch_output_shape=[512, 512],
        stride_shape=[256, 256],
        save_resolution={"units": "baseline", "resolution": 1.0},
    )

    # Setting the save directory and delete previous results
    wsi_prediction_dir = "./tmp/wsi_prediction/"
    if os.path.exists(wsi_prediction_dir):
        shutil.rmtree(wsi_prediction_dir)

    predictor = SemanticSegmentor(
        model=grandQC_model, num_loader_workers=6, batch_size=32
    )
    wsi_output = predictor.predict(
        imgs=["./temp_compressed_image.jpg"],
        mode="tile",
        device="cuda",
        ioconfig=iostate,
        crash_on_exception=True,
        save_dir=wsi_prediction_dir,
    )
    mask_path = wsi_output[0][1]
    mask_path = f"{mask_path}.raw.0.npy"
    mask = np.load(mask_path)

    tissue_mask = np.where(mask[:, :, 0] > 0.5, 255, 0)
    tissue_mask = tissue_mask.astype(np.uint8)

    del model
    torch.cuda.empty_cache()

    if os.path.exists("./temp_compressed_image.jpg"):
        os.remove("./temp_compressed_image.jpg")
    if os.path.exists("./tmp/"):
        shutil.rmtree("./tmp/")

    return tissue_mask


def main():
    """Main processing function."""
    print("Starting tissue detection analysis...")

    # Initialize setup (only need directory, no longer need model)
    tis_det_dir_mask = os.path.join(OUTPUT_DIR, "tis_det_mask/")
    os.makedirs(tis_det_dir_mask, exist_ok=True)

    slide_names = get_slide_names()

    # Process all slides
    successful_count = 0
    total_slides = len(slide_names)

    for slide_name in slide_names:
        print(f"\nWorking with: {slide_name}")
        slide_path = os.path.join(SLIDE_DIR, slide_name)

        # Process slide and get mask
        mask_result = process_single_slide(slide_path, MODEL_WEIGHT_PATH)

        if mask_result is not None:
            #     # Convert mask to proper format for saving

            # Save the mask
            mask_filename = f"{slide_name}_MASK.png"
            mask_path = os.path.join(tis_det_dir_mask, mask_filename)
            Image.fromarray(mask_result).save(mask_path)

            print(f"Successfully processed {slide_name}")
            successful_count += 1
        else:
            print(f"Failed to process {slide_name}")

    print(
        f"\nProcessing complete: {successful_count}/{total_slides} slides processed successfully"
    )


if __name__ == "__main__":
    main()
